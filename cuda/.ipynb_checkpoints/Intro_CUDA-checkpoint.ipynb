{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea9838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a custom stylesheet in IJulia\n",
    "file = open(\"./../style.css\") # A .css file in the same folder as this notebook file\n",
    "styl = read(file, String) # Read the file\n",
    "HTML(\"$styl\") # Output as HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e36910",
   "metadata": {},
   "source": [
    "## CUDA.jl (based on [CUDA.jl/ docs](https://cuda.juliagpu.org/stable/))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc99be72",
   "metadata": {},
   "source": [
    "<h2>In this notebook</h2>\n",
    "\n",
    "- [Set up](#Set-up)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74d17c",
   "metadata": {},
   "source": [
    "# Set up\n",
    "\n",
    "The Julia CUDA works with NVIDIA driver however we don't need to install the entire CUDA toolkit, this will be automatically done just adding CUDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cf42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the pkg \n",
    "using Pkg; \n",
    "Pkg.add(\"CUDA\")\n",
    "\n",
    "# get the tool version \n",
    "using CUDA \n",
    "CUDA.versioninfo()\n",
    "\n",
    "# test pkg\n",
    "Pkg.test(\"CUDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7b7bd7",
   "metadata": {},
   "source": [
    "# Really simple example\n",
    "\n",
    "In this first simple example we test the main differences on CPU and GPU implementation of a a multiply operation. Let's start with CPU implementation and creating a test problem for large array \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f993102",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2^22 # size of both vec\n",
    "x = fill(1.0f0, N) # x vec\n",
    "y = fill(2.0f0, N) # y vec\n",
    "\n",
    "# result and test\n",
    "r = x.*y\n",
    "\n",
    "using Test \n",
    "@test (all(r.==x[1]*y[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c878e94c",
   "metadata": {},
   "source": [
    "Let's know implemente a CPU paralalization with serial `serial_cpu_multiply` and `parallel_cpu_multiply` function : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd98056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the number of cpu threads \n",
    "JULIA_NUM_THREADS = 6\n",
    "\n",
    "# Declare parallel function cpu\n",
    "function serial_cpu_multiply(x,y)\n",
    "    for i in eachindex(x,y)\n",
    "        @inbounds r[i] = x[i]*y[i]\n",
    "    end\n",
    "    return r \n",
    "end\n",
    "\n",
    "\n",
    "# Declare parallel function cpu\n",
    "function parallel_cpu_multiply(x,y)\n",
    "    Threads.@threads for i in eachindex(x,y)\n",
    "        @inbounds r[i] = x[i]*y[i]\n",
    "    end\n",
    "    return r \n",
    "end\n",
    "\n",
    "# Execute function for y and x vec\n",
    "r_serial_cpu = serial_cpu_multiply(x,y)\n",
    "r_parallel_cpu = parallel_cpu_multiply(x,y)\n",
    "\n",
    "# Run test \n",
    "\n",
    "@test (all(r_parallel_cpu.==(x[1]*y[1])) && all(r_serial_cpu.==(x[1]*y[1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7e8613",
   "metadata": {},
   "source": [
    "Let's now measure the exution time with `BenchmarkTools` pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1372202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and install pkg\n",
    "Pkg.add(\"BenchmarkTools\")\n",
    "\n",
    "# Let's use it \n",
    "using BenchmarkTools\n",
    "\n",
    "# Serial and parallel cpu multiply\n",
    "@btime serial_cpu_multiply(x,y)\n",
    "@btime parallel_cpu_multiply(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea332a1f",
   "metadata": {},
   "source": [
    "Let's now implement it using GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641be1ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load CUDA \n",
    "using CUDA \n",
    "\n",
    "# define a vecotr on the GPU \n",
    "x_d = CUDA.fill(1.0f0, N)\n",
    "y_d = CUDA.fill(2.0f0, N)\n",
    "r_d = CUDA.fill(0.0f0, N)\n",
    "\n",
    "\n",
    "# define the function \n",
    "function multiply_gpu(y,x)\n",
    "    CUDA.@sync begin \n",
    "        return y.*x\n",
    "    end\n",
    "end\n",
    "\n",
    "# exute and measure time\n",
    "@btime multiply_gpu(x_d, y_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ae494a",
   "metadata": {},
   "source": [
    "The `@sync` macro is the interesting thing here. This will force the CPU to wait untill the GPU ends up its work and at that point will continue. But most of the time you don't need to synchronize explicitly: many operations, like copying memory from the GPU to the CPU, implicitly synchronize execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c0f50f",
   "metadata": {},
   "source": [
    "This way to perform high level computation is okay but we need to dive into to perform specific stuff under the hood. Let's implement our kernel to do that task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d1fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create my kernel\n",
    "function multiply_gpu_kernel!(x, y, r)\n",
    "    for i in 1:length(x)\n",
    "         r[i] = x[i]*y[i]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
