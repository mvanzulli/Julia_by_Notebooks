{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ea9838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Philosopher:400,700,400italic,700italic' rel='stylesheet' type='text/css'>\r\n",
       "\r\n",
       "<style>\r\n",
       "\r\n",
       "@font-face {\r\n",
       "    font-family: \"Computer Modern\";\r\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "\r\n",
       "/* Formatting for header cells */\r\n",
       ".text_cell_render h1 {\r\n",
       "    font-family: 'Philosopher', sans-serif;\r\n",
       "    font-weight: 400;\r\n",
       "    font-size: 2.2em;\r\n",
       "    line-height: 100%;\r\n",
       "    color: rgb(0, 80, 120);\r\n",
       "    margin-bottom: 0.1em;\r\n",
       "    margin-top: 0.1em;\r\n",
       "    display: block;\r\n",
       "}\t\r\n",
       ".text_cell_render h2 {\r\n",
       "    font-family: 'Philosopher', serif;\r\n",
       "    font-weight: 400;\r\n",
       "    font-size: 1.9em;\r\n",
       "    line-height: 100%;\r\n",
       "    color: rgb(200,100,0);\r\n",
       "    margin-bottom: 0.1em;\r\n",
       "    margin-top: 0.1em;\r\n",
       "    display: block;\r\n",
       "}\t\r\n",
       "\r\n",
       ".text_cell_render h3 {\r\n",
       "    font-family: 'Philosopher', serif;\r\n",
       "    margin-top:12px;\r\n",
       "    margin-bottom: 3px;\r\n",
       "    font-style: italic;\r\n",
       "    color: rgb(94,127,192);\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h4 {\r\n",
       "    font-family: 'Philosopher', serif;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h5 {\r\n",
       "    font-family: 'Alegreya Sans', sans-serif;\r\n",
       "    font-weight: 300;\r\n",
       "    font-size: 16pt;\r\n",
       "    color: grey;\r\n",
       "    font-style: italic;\r\n",
       "    margin-bottom: .1em;\r\n",
       "    margin-top: 0.1em;\r\n",
       "    display: block;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h6 {\r\n",
       "    font-family: 'PT Mono', sans-serif;\r\n",
       "    font-weight: 300;\r\n",
       "    font-size: 10pt;\r\n",
       "    color: grey;\r\n",
       "    margin-bottom: 1px;\r\n",
       "    margin-top: 1px;\r\n",
       "}\r\n",
       "\r\n",
       ".CodeMirror{\r\n",
       "        font-family: \"PT Mono\";\r\n",
       "        font-size: 100%;\r\n",
       "}\r\n",
       "\r\n",
       "</style>\r\n",
       "\r\n"
      ],
      "text/plain": [
       "HTML{String}(\"<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\\r\\n<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\\r\\n<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\\r\\n<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\\r\\n<link href='http://fonts.googleapis.com/css?family=Philosopher:400,700,400italic,700italic' rel='stylesheet' type='text/css'>\\r\\n\\r\\n<style>\\r\\n\\r\\n@font-face {\\r\\n    font-family: \\\"Computer Modern\\\";\\r\\n    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\\r\\n}\\r\\n\\r\\n\\r\\n\\r\\n/* Formatting for header cells */\\r\\n.text_cell_render h1 {\\r\\n    font-family: 'Philosopher', sans-serif;\\r\\n    font-weight: 400;\\r\\n    font-size: 2.2em;\\r\\n    line-height: 100%;\\r\\n    color: rgb(0, 80, 120);\\r\\n    margin-bottom: 0.1em;\\r\\n    margin-top: 0.1em;\\r\\n    display: block;\\r\\n}\\t\\r\\n.text_cell_render h2 {\\r\\n    font-family: 'Philosopher', serif;\\r\\n    font-weight: 400;\\r\\n    font-size: 1.9em;\\r\\n    line-height: 100%;\\r\\n    color: rgb(200,100,0);\\r\\n    margin-bottom: 0.1em;\\r\\n    margin-top: 0.1em;\\r\\n    display: block;\\r\\n}\\t\\r\\n\\r\\n.text_cell_render h3 {\\r\\n    font-family: 'Philosopher', serif;\\r\\n    margin-top:12px;\\r\\n    margin-bottom: 3px;\\r\\n    font-style: italic;\\r\\n    color: rgb(94,127,192);\\r\\n}\\r\\n\\r\\n.text_cell_render h4 {\\r\\n    font-family: 'Philosopher', serif;\\r\\n}\\r\\n\\r\\n.text_cell_render h5 {\\r\\n    font-family: 'Alegreya Sans', sans-serif;\\r\\n    font-weight: 300;\\r\\n    font-size: 16pt;\\r\\n    color: grey;\\r\\n    font-style: italic;\\r\\n    margin-bottom: .1em;\\r\\n    margin-top: 0.1em;\\r\\n    display: block;\\r\\n}\\r\\n\\r\\n.text_cell_render h6 {\\r\\n    font-family: 'PT Mono', sans-serif;\\r\\n    font-weight: 300;\\r\\n    font-size: 10pt;\\r\\n    color: grey;\\r\\n    margin-bottom: 1px;\\r\\n    margin-top: 1px;\\r\\n}\\r\\n\\r\\n.CodeMirror{\\r\\n        font-family: \\\"PT Mono\\\";\\r\\n        font-size: 100%;\\r\\n}\\r\\n\\r\\n</style>\\r\\n\\r\\n\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up a custom stylesheet in IJulia\n",
    "file = open(\"./../style.css\") # A .css file in the same folder as this notebook file\n",
    "styl = read(file, String) # Read the file\n",
    "HTML(\"$styl\") # Output as HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e36910",
   "metadata": {},
   "source": [
    "## CUDA.jl (based on [CUDA.jl/ docs](https://cuda.juliagpu.org/stable/))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc99be72",
   "metadata": {},
   "source": [
    "<h2>In this notebook</h2>\n",
    "\n",
    "- [Set up](#Set-up)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74d17c",
   "metadata": {},
   "source": [
    "# Set up\n",
    "\n",
    "The Julia CUDA works with NVIDIA driver however we don't need to install the entire CUDA toolkit, this will be automatically done just adding CUDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cf42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the pkg \n",
    "using Pkg; \n",
    "Pkg.add(\"CUDA\")\n",
    "\n",
    "# get the tool version \n",
    "using CUDA \n",
    "CUDA.versioninfo()\n",
    "\n",
    "# test pkg\n",
    "Pkg.test(\"CUDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7b7bd7",
   "metadata": {},
   "source": [
    "# Really simple example\n",
    "\n",
    "In this first simple example we test the main differences on CPU and GPU implementation of a a multiply operation. Let's start with CPU implementation and creating a test problem for large array \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f993102",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2^22 # size of both vec\n",
    "x = fill(1.0f0, N) # x vec\n",
    "y = fill(2.0f0, N) # y vec\n",
    "\n",
    "# result and test\n",
    "r = x.*y\n",
    "\n",
    "using Test \n",
    "@test (all(r.==x[1]*y[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c878e94c",
   "metadata": {},
   "source": [
    "Let's know implemente a CPU paralalization with serial `serial_cpu_multiply` and `parallel_cpu_multiply` function : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd98056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the number of cpu threads \n",
    "JULIA_NUM_THREADS = 6\n",
    "\n",
    "# Declare parallel function cpu\n",
    "function serial_cpu_multiply(x,y)\n",
    "    for i in eachindex(x,y)\n",
    "        @inbounds r[i] = x[i]*y[i]\n",
    "    end\n",
    "    return r \n",
    "end\n",
    "\n",
    "\n",
    "# Declare parallel function cpu\n",
    "function parallel_cpu_multiply(x,y)\n",
    "    Threads.@threads for i in eachindex(x,y)\n",
    "        @inbounds r[i] = x[i]*y[i]\n",
    "    end\n",
    "    return r \n",
    "end\n",
    "\n",
    "# Execute function for y and x vec\n",
    "r_serial_cpu = serial_cpu_multiply(x,y)\n",
    "r_parallel_cpu = parallel_cpu_multiply(x,y)\n",
    "\n",
    "# Run test \n",
    "\n",
    "@test (all(r_parallel_cpu.==(x[1]*y[1])) && all(r_serial_cpu.==(x[1]*y[1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7e8613",
   "metadata": {},
   "source": [
    "Let's now measure the exution time with `BenchmarkTools` pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1372202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and install pkg\n",
    "Pkg.add(\"BenchmarkTools\")\n",
    "\n",
    "# Let's use it \n",
    "using BenchmarkTools\n",
    "\n",
    "# Serial and parallel cpu multiply\n",
    "@btime serial_cpu_multiply(x,y)\n",
    "@btime parallel_cpu_multiply(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea332a1f",
   "metadata": {},
   "source": [
    "Let's now implement it using GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641be1ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load CUDA \n",
    "using CUDA \n",
    "\n",
    "# define a vecotr on the GPU \n",
    "x_d = CUDA.fill(1.0f0, N)\n",
    "y_d = CUDA.fill(2.0f0, N)\n",
    "r_d = CUDA.fill(0.0f0, N)\n",
    "\n",
    "\n",
    "# define the function \n",
    "function multiply_gpu(y,x)\n",
    "    CUDA.@sync begin \n",
    "        return y.*x\n",
    "    end\n",
    "end\n",
    "\n",
    "# exute and measure time\n",
    "@btime multiply_gpu(x_d, y_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ae494a",
   "metadata": {},
   "source": [
    "The `@sync` macro is the interesting thing here. This will force the CPU to wait untill the GPU ends up its work and at that point will continue. But most of the time you don't need to synchronize explicitly: many operations, like copying memory from the GPU to the CPU, implicitly synchronize execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ab8b39",
   "metadata": {},
   "source": [
    "This way to perform high level computation is okay but we need to dive into to perform specific stuff under the hood. Let's implement our kernel to do that task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cc4464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create my kernel\n",
    "function multiply_gpu_kernel!(x, y, r)\n",
    "    for i in 1:length(x)\n",
    "         r[i] = x[i]*y[i]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "\n",
    "# execute the kerenel with autmatic number of threads and blocks \n",
    "@cuda multiply_gpu_kernel!(x_d, y_d, r_d)\n",
    "\n",
    "# lets create a benchmark function to test it \n",
    "function bench_multiply_gpu(x_d, y_d, r_d)\n",
    "    CUDA.@sync begin\n",
    "        @cuda multiply_gpu_kernel!(x_d, y_d, r_d)\n",
    "    end\n",
    "end\n",
    "\n",
    "@btime bench_multiply_gpu(x_d, y_d, r_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b968943",
   "metadata": {},
   "source": [
    "After using  `CuArrays` `x_d` and `y_d`, we can lunch our kernel launch via `@cuda`. The `@cuda` macro statement, it will compile the kernel `(bench_multiply_gpu!)` for execution on the GPU. Once compiled, future invocations are fast. You can see what `@cuda` expands to using `?@cuda` from the Julia prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691e2fce",
   "metadata": {},
   "source": [
    "```\n",
    "cuda\n",
    "  @cuda [kwargs...] func(args...)\n",
    "\n",
    "  High-level interface for executing code on a GPU. The @cuda macro should\n",
    "  prefix a call, with func a callable function or object that should return\n",
    "  nothing. It will be compiled to a CUDA function upon first use, and to a\n",
    "  certain extent arguments will be converted and managed automatically using\n",
    "  cudaconvert. Finally, a call to cudacall is performed, scheduling a kernel\n",
    "  launch on the current CUDA context.\n",
    "\n",
    "  Several keyword arguments are supported that influence the behavior of\n",
    "  @cuda.\n",
    "\n",
    "    •  launch: whether to launch this kernel, defaults to true. If\n",
    "       false the returned kernel object should be launched by calling\n",
    "       it and passing arguments again.\n",
    "\n",
    "    •  dynamic: use dynamic parallelism to launch device-side kernels,\n",
    "       defaults to false.\n",
    "\n",
    "    •  arguments that influence kernel compilation: see cufunction and\n",
    "       dynamic_cufunction\n",
    "\n",
    "    •  arguments that influence kernel launch: see CUDA.HostKernel and\n",
    "       CUDA.DeviceKernel\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4aec84",
   "metadata": {},
   "source": [
    "# Profiling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e53664",
   "metadata": {},
   "source": [
    "Often is really important obtain a profiling for our GPU program, to check coalsceed access, race conditions problems, memory managment acces, etc. For that, we can call `nvprof` tool from NVIDIA. On a Unix system we should execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9d8bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "$ nvprof --profile-from-start off /path/to/julia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f22aec",
   "metadata": {},
   "source": [
    "The `/path/to/julia` is the path to julia binary. Note that we don't initialize immediately the profiler but we can call the CUDA API's with the macro @profile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0861c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: CUDA not defined\nin expression starting at In[1]:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: CUDA not defined\nin expression starting at In[1]:1",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ :0",
      " [2] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "CUDA.@profile bench_multiply_gpu(x_d, y_d, r_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dbced5",
   "metadata": {},
   "source": [
    "But nvprof is not longer used for GPUs with compute capalities newer than 7.0, instead we need nsys (Nsight system), to set nsys to julia we run: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38653f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ nsys lunch julia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
