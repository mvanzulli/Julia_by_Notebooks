{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization packages playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define f\n",
    "a = 1.0\n",
    "b = 100.0\n",
    "\n",
    "my_f_calls = [0]\n",
    "\n",
    "\"Rossenbrok's function\"\n",
    "function rosenbrock(x::Vector{<:Real}, a::Real, b::Real, my_f_calls=my_f_calls) \n",
    "    push!(my_f_calls, 1)\n",
    "    (a - x[1])^2 + b * (x[2] - x[1]^2)^2\n",
    "end\n",
    "\"Closure\"\n",
    "f = x -> rosenbrock(x, a, b, my_f_calls);\n",
    "\n",
    "\"Rossenbrok's function gradient\"\n",
    "function g!(G, x)\n",
    "    G[1] = -2.0 * (1.0 - x[1]) - 400.0 * (x[2] - x[1]^2) * x[1]\n",
    "    G[2] = 200.0 * (x[2] - x[1]^2)\n",
    "end\n",
    "\n",
    "\"Rossenbrok's Hessian matrix\"\n",
    "function ùêªrosenbrock!(H, x)\n",
    "    H[1, 1] = 2.0 - 400.0 * x[2] + 1200.0 * x[1]^2\n",
    "    H[1, 2] = -400.0 * x[1]\n",
    "    H[2, 1] = -400.0 * x[1]\n",
    "    H[2, 2] = 200.0\n",
    "end;\n",
    "    \n",
    "\"Analytic solution\"\n",
    "x‚Çò·µ¢‚Çô = [a, a^2];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots; pyplot()\n",
    "x  = [-2:0.05:2;]\n",
    "y = [-1:0.05:3;]\n",
    "z = [f([x,y]) for x in x, y in y]\n",
    "\n",
    "minZ = minimum(z[:]);  \n",
    "maxZ = maximum(z[:]);\n",
    "\n",
    "COL = append!([colorant\"blue\",colorant\"lime\"],range(colorant\"yellow\",colorant\"red\",length=20))\n",
    "c =  minZ .+ (maxZ-minZ).*log.(1 .+z .- minZ) ./ log(1+maxZ-minZ)\n",
    "\n",
    "Plots.plot(x,y,z,st=:surface,color=cgrad(COL,scale=:exp),#cgrad(:jet,c),\n",
    "xlabel = \"x\",ylabel=\"y\",zlabel=\"f(x,y)\",zguidefontrotation=45,camera=(-30,30))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optim.jl: Gradient required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Optim\n",
    "\n",
    "# Box \n",
    "lower = [0.3, -2.1]\n",
    "upper = [30.0, 40.0]\n",
    "\n",
    "# Initial guess\n",
    "x‚ÇÄ = [0.4,0.5];"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LBFGS{Nothing, LineSearches.InitialStatic{Float64}, LineSearches.HagerZhang{Float64, Base.RefValue{Bool}}, Optim.var\"#20#22\"}(10, LineSearches.InitialStatic{Float64}\n",
       "  alpha: Float64 1.0\n",
       "  scaled: Bool false\n",
       ", LineSearches.HagerZhang{Float64, Base.RefValue{Bool}}\n",
       "  delta: Float64 0.1\n",
       "  sigma: Float64 0.9\n",
       "  alphamax: Float64 Inf\n",
       "  rho: Float64 5.0\n",
       "  epsilon: Float64 1.0e-6\n",
       "  gamma: Float64 0.66\n",
       "  linesearchmax: Int64 50\n",
       "  psi3: Float64 0.1\n",
       "  display: Int64 0\n",
       "  mayterminate: Base.RefValue{Bool}\n",
       ", nothing, Optim.var\"#20#22\"(), Flat(), true)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inner_optimizer = GradientDescent()\n",
    "inner_optimizer = ConjugateGradient()\n",
    "momentum  = 10\n",
    "inner_optimizer = LBFGS(m = momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------ForwardDiff with ‚àá--------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary(res) = \"Fminbox with L-BFGS\"\n",
      "minimum(res) = 5.361093300320716e-17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optim.minimizer(res) = [0.9999999926780513, 0.9999999853561207]\n",
      "Optim.iterations(res) = 4\n",
      "Optim.iteration_limit_reached(res) = false\n",
      "Optim.f_calls(res) = 78\n",
      "Optim.converged(res) = true\n",
      "-------Grdient--------\n",
      "summary(res) = \"Fminbox with L-BFGS\"\n",
      "minimum(res) = 1.383848755571263e-22\n",
      "Optim.minimizer(res) = [1.0000000000117624, 1.0000000000235425]\n",
      "Optim.iterations(res) = 4\n",
      "Optim.iteration_limit_reached(res) = false\n",
      "Optim.f_calls(res) = 74\n",
      "Optim.converged(res) = true\n",
      "-------My fcalls--------\n",
      "sum(my_f_calls) = 466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "466"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set tolerances\n",
    "#Ncalls to f \n",
    "outer_iters = 40\n",
    "#Ncalls to alg step\n",
    "iters = 30\n",
    "# gradient tolerance \n",
    "GTOL = 1e-12\n",
    "options = Optim.Options(g_tol = 1e-12, outer_iterations = outer_iters, iterations = iters, store_trace = true)\n",
    "\n",
    "# Forward Diff\n",
    "res_fdif = optimize(f, lower, upper, x‚ÇÄ, Fminbox(inner_optimizer),options, autodiff = :finite )\n",
    "res = optimize(f, g!, lower, upper, x‚ÇÄ, Fminbox(inner_optimizer))\n",
    "\n",
    "function show_results(res)\n",
    "    @show summary(res)\n",
    "    @show minimum(res)\n",
    "    @show Optim.minimizer(res)\n",
    "    @show Optim.iterations(res)\n",
    "    @show Optim.iteration_limit_reached(res)\n",
    "    # @show length(Optim.f_trace(res))\n",
    "    @show Optim.f_calls(res)\n",
    "    @show Optim.converged(res)\n",
    "end\n",
    "\n",
    "\n",
    "println(\"-------ForwardDiff with ‚àá--------\")\n",
    "show_results(res_fdif)\n",
    "\n",
    "println(\"-------Grdient--------\")\n",
    "show_results(res)\n",
    "\n",
    "println(\"-------My fcalls--------\")\n",
    "@show sum(my_f_calls)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optim.jl: Gradient free "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Nelder Mead--------\n",
      "summary(res) = \"Fminbox with Nelder-Mead\"\n",
      "minimum(res) = 3.0143331585332986e-9\n",
      "Optim.minimizer(res) = [0.9999499855832705, 0.9999022383782905]\n",
      "Optim.iterations(res) = 5\n",
      "Optim.iteration_limit_reached(res) = true\n",
      "Optim.f_calls(res) = 350\n",
      "Optim.converged(res) = true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inner_optimizer = NelderMead()\n",
    "res_nmead = optimize(f, lower, upper, x‚ÇÄ, Fminbox(inner_optimizer),options)\n",
    "\n",
    "\n",
    "println(\"-------Nelder Mead--------\")\n",
    "show_results(res_nmead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black Box Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization with optimizer DiffEvoOpt{FitPopulation{Float64}, RadiusLimitedSelector, BlackBoxOptim.AdaptiveDiffEvoRandBin{3}, RandomBound{ContinuousRectSearchSpace}}\n",
      "0.00 secs, 0 evals, 0 steps\n",
      "DE modify state:\n",
      "\n",
      "Optimization stopped after 19532 steps and 0.03 seconds\n",
      "Termination reason: Too many steps (101) without any function evaluations (probably search has converged)\n",
      "Steps per second = 658064.81\n",
      "Function evals per second = 630100.76\n",
      "Improvements/step = Inf\n",
      "Total function evaluations = 18702\n",
      "\n",
      "\n",
      "Best candidate found: [1.0, 1.0]\n",
      "\n",
      "Fitness: 0.000000000\n",
      "\n",
      "-------BBO Otpim--------\n",
      "best_candidate(res) = [1.0, 1.0]\n",
      "best_fitness(res) = 0.0\n",
      "minimum(res) = [1.0, 1.0]\n",
      "iteration_converged(res) = true\n",
      "res.stop_reason = \"Too many steps (101) without any function evaluations (probably search has converged)\"\n",
      "fitness_scheme(res) = ScalarFitnessScheme{true}()\n",
      "res.iterations = 19532\n",
      "res.f_calls = 18702\n",
      "-------my_f_calls--------\n",
      "sum(my_f_calls) = 18703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18703"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using BlackBoxOptim\n",
    "\n",
    "\n",
    "method = :probabilistic_descent\n",
    "method = :de_rand_1_bin_radiuslimited\n",
    "method = :adaptive_de_rand_1_bin_radiuslimited\n",
    "\n",
    "my_f_calls = [0]\n",
    "\n",
    "good_guess = [3.0, 7.2]\n",
    "two_good_guesses = [[3.0, 7.2], [3.0, 7.2]]\n",
    "res = bboptimize(f, two_good_guesses; \n",
    "SearchRange = [(lower[1], upper[1]), (lower[2], upper[2])], \n",
    " Method = method,\n",
    " MaxTime = 10,\n",
    " MaxFuncEvals = 20,\n",
    " FitnessScheme  = MinimizingFitnessScheme, # fitness scheme to be used\n",
    " FitnessTolerance = 1e-8, # fitness scheme to be used\n",
    " MaxSteps = 10000,\n",
    " TraceMode = :verbose,\n",
    " PopulationSize = 60,\n",
    " TargetFitness = nothing, # optimal (target) fitness, if known\n",
    " SaveTrace      = true,\n",
    " SaveFitnessTraceToCsv = false,\n",
    " SaveParameters = true,\n",
    " MaxStepsWithoutProgress = 10000,\n",
    " RngSeed        = 1234,   # The specific random seed to set before any random numbers are generated. The seed is randomly selected if RandomizeRngSeed is true, and this parameter is updated with its actual value.\n",
    " RandomizeRngSeed = false,\n",
    " )\n",
    "\n",
    "# Maximum time allowed in seconds. \n",
    "\n",
    "# Number of function evaluations allowed, this needs  MaxTime to be false then the MaxFuncEvals plays a role\n",
    "println(\"-------BBO Otpim--------\")\n",
    "# Access to the solution \n",
    "@show best_candidate(res)\n",
    "@show best_fitness(res)\n",
    "@show minimum(res)\n",
    "@show iteration_converged(res)\n",
    "@show res.stop_reason\n",
    "@show fitness_scheme(res)\n",
    "@show res.iterations\n",
    "@show res.f_calls\n",
    "\n",
    "println(\"-------my_f_calls--------\")\n",
    "\n",
    "@show sum(my_f_calls)\n",
    "# writetable(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
